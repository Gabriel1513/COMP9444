{"cells":[{"metadata":{"_cell_guid":"4d5be342-abe9-4c95-98fd-c904762ecca9","_uuid":"47570c242f4774c5d670093b822cf6a3f3a91ba9","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nprint(keras.__version__)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom math import nan\nfrom keras.callbacks import ModelCheckpoint\n\n!pip install git+https://www.github.com/keras-team/keras-contrib.git\nfrom keras_contrib.layers import CRF\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":2,"outputs":[{"output_type":"stream","text":"2.2.4\nCollecting git+https://www.github.com/keras-team/keras-contrib.git\n  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-6w9n305p\n  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-6w9n305p\nRequirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /opt/conda/lib/python3.6/site-packages\nRequirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages (from keras-contrib==2.0.8) (2.2.4)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (2.9.0)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.2.1)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.0.8)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.1.0)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.12.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.17.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (5.1.2)\nBuilding wheels for collected packages: keras-contrib\n  Building wheel for keras-contrib (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101066 sha256=53a6ea9790672f427994a36b9a18c0e9902a47bb7a7b7daedb1ec68239750f7f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3efv6ne7/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\nSuccessfully built keras-contrib\nentity-annotated-corpus\n\n","name":"stdout"}]},{"metadata":{"_cell_guid":"46eeeccc-37ad-4d58-b0c5-71dcbb4b935b","_uuid":"64d208ee42a7c5919fc1f7f0937b7b6fcb9c3ea7"},"cell_type":"markdown","source":"\n## Importing the dataset for named entity recognition model"},{"metadata":{"_cell_guid":"fab9a876-dd53-4636-a48e-3a87a5ba9370","_uuid":"39f851aae0e531c23978926c6ad9bc3d2c739705","trusted":true},"cell_type":"code","source":"dframe = pd.read_csv(\"../input/entity-annotated-corpus/ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)","execution_count":3,"outputs":[{"output_type":"stream","text":"b'Skipping line 281837: expected 25 fields, saw 34\\n'\n","name":"stderr"}]},{"metadata":{"_cell_guid":"0049ec5e-3b99-4059-a09c-7395f1fa3ab7","_uuid":"ce5d3d143151edbe4885ea10ca1994fb2687038a","trusted":true},"cell_type":"code","source":"dframe","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"         Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n0                 0  thousand         of        demonstr           NNS   \n1                 1        of   demonstr            have           VBP   \n2                 2  demonstr       have           march           VBN   \n3                 3      have      march         through            IN   \n4                 4     march    through          london           NNP   \n...             ...       ...        ...             ...           ...   \n1050790     1048570      they    respond              to            TO   \n1050791     1048571   respond         to             the            DT   \n1050792     1048572        to        the          attack            NN   \n1050793     1048573       the     attack            with            IN   \n1050794     1048574    attack       with     machine-gun            JJ   \n\n         next-next-shape next-next-word next-pos next-shape      next-word  \\\n0              lowercase  demonstrators       IN  lowercase             of   \n1              lowercase           have      NNS  lowercase  demonstrators   \n2              lowercase        marched      VBP  lowercase           have   \n3              lowercase        through      VBN  lowercase        marched   \n4            capitalized         London       IN  lowercase        through   \n...                  ...            ...      ...        ...            ...   \n1050790        lowercase             to      VBD  lowercase      responded   \n1050791        lowercase            the       TO  lowercase             to   \n1050792        lowercase         attack       DT  lowercase            the   \n1050793        lowercase           with       NN  lowercase         attack   \n1050794  contains-hyphen    machine-gun       IN  lowercase           with   \n\n         ... prev-prev-lemma prev-prev-pos prev-prev-shape prev-prev-word  \\\n0        ...      __start2__    __START2__        wildcard     __START2__   \n1        ...      __start1__    __START1__        wildcard     __START1__   \n2        ...        thousand           NNS     capitalized      Thousands   \n3        ...              of            IN       lowercase             of   \n4        ...        demonstr           NNS       lowercase  demonstrators   \n...      ...             ...           ...             ...            ...   \n1050790  ...            forc           NNS       lowercase         forces   \n1050791  ...            said           VBD       lowercase           said   \n1050792  ...            they           PRP       lowercase           they   \n1050793  ...         respond           VBD       lowercase      responded   \n1050794  ...              to            TO       lowercase             to   \n\n          prev-shape      prev-word sentence_idx        shape           word  \\\n0           wildcard     __START1__          1.0  capitalized      Thousands   \n1        capitalized      Thousands          1.0    lowercase             of   \n2          lowercase             of          1.0    lowercase  demonstrators   \n3          lowercase  demonstrators          1.0    lowercase           have   \n4          lowercase           have          1.0    lowercase        marched   \n...              ...            ...          ...          ...            ...   \n1050790    lowercase           said      47959.0    lowercase           they   \n1050791    lowercase           they      47959.0    lowercase      responded   \n1050792    lowercase      responded      47959.0    lowercase             to   \n1050793    lowercase             to      47959.0    lowercase            the   \n1050794    lowercase            the      47959.0    lowercase         attack   \n\n        tag  \n0         O  \n1         O  \n2         O  \n3         O  \n4         O  \n...      ..  \n1050790   O  \n1050791   O  \n1050792   O  \n1050793   O  \n1050794   O  \n\n[1050795 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>lemma</th>\n      <th>next-lemma</th>\n      <th>next-next-lemma</th>\n      <th>next-next-pos</th>\n      <th>next-next-shape</th>\n      <th>next-next-word</th>\n      <th>next-pos</th>\n      <th>next-shape</th>\n      <th>next-word</th>\n      <th>...</th>\n      <th>prev-prev-lemma</th>\n      <th>prev-prev-pos</th>\n      <th>prev-prev-shape</th>\n      <th>prev-prev-word</th>\n      <th>prev-shape</th>\n      <th>prev-word</th>\n      <th>sentence_idx</th>\n      <th>shape</th>\n      <th>word</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>thousand</td>\n      <td>of</td>\n      <td>demonstr</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>...</td>\n      <td>__start2__</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>1.0</td>\n      <td>capitalized</td>\n      <td>Thousands</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>of</td>\n      <td>demonstr</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>lowercase</td>\n      <td>have</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>...</td>\n      <td>__start1__</td>\n      <td>__START1__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>capitalized</td>\n      <td>Thousands</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>demonstr</td>\n      <td>have</td>\n      <td>march</td>\n      <td>VBN</td>\n      <td>lowercase</td>\n      <td>marched</td>\n      <td>VBP</td>\n      <td>lowercase</td>\n      <td>have</td>\n      <td>...</td>\n      <td>thousand</td>\n      <td>NNS</td>\n      <td>capitalized</td>\n      <td>Thousands</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>have</td>\n      <td>march</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>through</td>\n      <td>VBN</td>\n      <td>lowercase</td>\n      <td>marched</td>\n      <td>...</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>have</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>march</td>\n      <td>through</td>\n      <td>london</td>\n      <td>NNP</td>\n      <td>capitalized</td>\n      <td>London</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>through</td>\n      <td>...</td>\n      <td>demonstr</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>lowercase</td>\n      <td>have</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>marched</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>through</td>\n      <td>london</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>NNP</td>\n      <td>capitalized</td>\n      <td>London</td>\n      <td>...</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>lowercase</td>\n      <td>have</td>\n      <td>lowercase</td>\n      <td>marched</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>through</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>london</td>\n      <td>to</td>\n      <td>protest</td>\n      <td>VB</td>\n      <td>lowercase</td>\n      <td>protest</td>\n      <td>TO</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>...</td>\n      <td>march</td>\n      <td>VBN</td>\n      <td>lowercase</td>\n      <td>marched</td>\n      <td>lowercase</td>\n      <td>through</td>\n      <td>1.0</td>\n      <td>capitalized</td>\n      <td>London</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>to</td>\n      <td>protest</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>VB</td>\n      <td>lowercase</td>\n      <td>protest</td>\n      <td>...</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>through</td>\n      <td>capitalized</td>\n      <td>London</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>protest</td>\n      <td>the</td>\n      <td>war</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>war</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>...</td>\n      <td>london</td>\n      <td>NNP</td>\n      <td>capitalized</td>\n      <td>London</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>protest</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>the</td>\n      <td>war</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>war</td>\n      <td>...</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>lowercase</td>\n      <td>protest</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>war</td>\n      <td>in</td>\n      <td>iraq</td>\n      <td>NNP</td>\n      <td>capitalized</td>\n      <td>Iraq</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>...</td>\n      <td>protest</td>\n      <td>VB</td>\n      <td>lowercase</td>\n      <td>protest</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>war</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>in</td>\n      <td>iraq</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>lowercase</td>\n      <td>and</td>\n      <td>NNP</td>\n      <td>capitalized</td>\n      <td>Iraq</td>\n      <td>...</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>lowercase</td>\n      <td>war</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>iraq</td>\n      <td>and</td>\n      <td>demand</td>\n      <td>VB</td>\n      <td>lowercase</td>\n      <td>demand</td>\n      <td>CC</td>\n      <td>lowercase</td>\n      <td>and</td>\n      <td>...</td>\n      <td>war</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>war</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>1.0</td>\n      <td>capitalized</td>\n      <td>Iraq</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>and</td>\n      <td>demand</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>VB</td>\n      <td>lowercase</td>\n      <td>demand</td>\n      <td>...</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>capitalized</td>\n      <td>Iraq</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>and</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>demand</td>\n      <td>the</td>\n      <td>withdraw</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>withdrawal</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>...</td>\n      <td>iraq</td>\n      <td>NNP</td>\n      <td>capitalized</td>\n      <td>Iraq</td>\n      <td>lowercase</td>\n      <td>and</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>demand</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>the</td>\n      <td>withdraw</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>withdrawal</td>\n      <td>...</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>lowercase</td>\n      <td>and</td>\n      <td>lowercase</td>\n      <td>demand</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>withdraw</td>\n      <td>of</td>\n      <td>british</td>\n      <td>JJ</td>\n      <td>capitalized</td>\n      <td>British</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>...</td>\n      <td>demand</td>\n      <td>VB</td>\n      <td>lowercase</td>\n      <td>demand</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>withdrawal</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>of</td>\n      <td>british</td>\n      <td>troop</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>troops</td>\n      <td>JJ</td>\n      <td>capitalized</td>\n      <td>British</td>\n      <td>...</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>lowercase</td>\n      <td>withdrawal</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>british</td>\n      <td>troop</td>\n      <td>from</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>from</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>troops</td>\n      <td>...</td>\n      <td>withdraw</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>withdrawal</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>1.0</td>\n      <td>capitalized</td>\n      <td>British</td>\n      <td>B-gpe</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>troop</td>\n      <td>from</td>\n      <td>that</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>that</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>from</td>\n      <td>...</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>capitalized</td>\n      <td>British</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>troops</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>from</td>\n      <td>that</td>\n      <td>countri</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>country</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>that</td>\n      <td>...</td>\n      <td>british</td>\n      <td>JJ</td>\n      <td>capitalized</td>\n      <td>British</td>\n      <td>lowercase</td>\n      <td>troops</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>from</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>that</td>\n      <td>countri</td>\n      <td>.</td>\n      <td>.</td>\n      <td>punct</td>\n      <td>.</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>country</td>\n      <td>...</td>\n      <td>troop</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>troops</td>\n      <td>lowercase</td>\n      <td>from</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>that</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>countri</td>\n      <td>.</td>\n      <td>__end1__</td>\n      <td>__END1__</td>\n      <td>wildcard</td>\n      <td>__END1__</td>\n      <td>.</td>\n      <td>punct</td>\n      <td>.</td>\n      <td>...</td>\n      <td>from</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>from</td>\n      <td>lowercase</td>\n      <td>that</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>country</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>.</td>\n      <td>__end1__</td>\n      <td>__end2__</td>\n      <td>__END2__</td>\n      <td>wildcard</td>\n      <td>__END2__</td>\n      <td>__END1__</td>\n      <td>wildcard</td>\n      <td>__END1__</td>\n      <td>...</td>\n      <td>that</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>that</td>\n      <td>lowercase</td>\n      <td>country</td>\n      <td>1.0</td>\n      <td>punct</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>famili</td>\n      <td>of</td>\n      <td>soldier</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>soldiers</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>...</td>\n      <td>__start2__</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>2.0</td>\n      <td>capitalized</td>\n      <td>Families</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>of</td>\n      <td>soldier</td>\n      <td>kill</td>\n      <td>VBN</td>\n      <td>lowercase</td>\n      <td>killed</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>soldiers</td>\n      <td>...</td>\n      <td>__start1__</td>\n      <td>__START1__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>capitalized</td>\n      <td>Families</td>\n      <td>2.0</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>soldier</td>\n      <td>kill</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>VBN</td>\n      <td>lowercase</td>\n      <td>killed</td>\n      <td>...</td>\n      <td>famili</td>\n      <td>NNS</td>\n      <td>capitalized</td>\n      <td>Families</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>2.0</td>\n      <td>lowercase</td>\n      <td>soldiers</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>kill</td>\n      <td>in</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>...</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>lowercase</td>\n      <td>soldiers</td>\n      <td>2.0</td>\n      <td>lowercase</td>\n      <td>killed</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>in</td>\n      <td>the</td>\n      <td>conflict</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>conflict</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>...</td>\n      <td>soldier</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>soldiers</td>\n      <td>lowercase</td>\n      <td>killed</td>\n      <td>2.0</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>the</td>\n      <td>conflict</td>\n      <td>join</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>joined</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>conflict</td>\n      <td>...</td>\n      <td>kill</td>\n      <td>VBN</td>\n      <td>lowercase</td>\n      <td>killed</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>2.0</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1050765</th>\n      <td>1048545</td>\n      <td>two</td>\n      <td>more</td>\n      <td>land</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>landed</td>\n      <td>JJR</td>\n      <td>lowercase</td>\n      <td>more</td>\n      <td>...</td>\n      <td>__start2__</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>47957.0</td>\n      <td>capitalized</td>\n      <td>Two</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050766</th>\n      <td>1048546</td>\n      <td>more</td>\n      <td>land</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>landed</td>\n      <td>...</td>\n      <td>__start1__</td>\n      <td>__START1__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>capitalized</td>\n      <td>Two</td>\n      <td>47957.0</td>\n      <td>lowercase</td>\n      <td>more</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050767</th>\n      <td>1048547</td>\n      <td>land</td>\n      <td>in</td>\n      <td>field</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>fields</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>...</td>\n      <td>two</td>\n      <td>CD</td>\n      <td>capitalized</td>\n      <td>Two</td>\n      <td>lowercase</td>\n      <td>more</td>\n      <td>47957.0</td>\n      <td>lowercase</td>\n      <td>landed</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050768</th>\n      <td>1048548</td>\n      <td>in</td>\n      <td>field</td>\n      <td>belong</td>\n      <td>VBG</td>\n      <td>lowercase</td>\n      <td>belonging</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>fields</td>\n      <td>...</td>\n      <td>more</td>\n      <td>JJR</td>\n      <td>lowercase</td>\n      <td>more</td>\n      <td>lowercase</td>\n      <td>landed</td>\n      <td>47957.0</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050769</th>\n      <td>1048549</td>\n      <td>field</td>\n      <td>belong</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>VBG</td>\n      <td>lowercase</td>\n      <td>belonging</td>\n      <td>...</td>\n      <td>land</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>landed</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>47957.0</td>\n      <td>lowercase</td>\n      <td>fields</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050770</th>\n      <td>1048550</td>\n      <td>belong</td>\n      <td>to</td>\n      <td>a</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>a</td>\n      <td>TO</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>...</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>in</td>\n      <td>lowercase</td>\n      <td>fields</td>\n      <td>47957.0</td>\n      <td>lowercase</td>\n      <td>belonging</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050771</th>\n      <td>1048551</td>\n      <td>to</td>\n      <td>a</td>\n      <td>nearbi</td>\n      <td>JJ</td>\n      <td>lowercase</td>\n      <td>nearby</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>a</td>\n      <td>...</td>\n      <td>field</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>fields</td>\n      <td>lowercase</td>\n      <td>belonging</td>\n      <td>47957.0</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050772</th>\n      <td>1048552</td>\n      <td>a</td>\n      <td>nearbi</td>\n      <td>villag</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>village</td>\n      <td>JJ</td>\n      <td>lowercase</td>\n      <td>nearby</td>\n      <td>...</td>\n      <td>belong</td>\n      <td>VBG</td>\n      <td>lowercase</td>\n      <td>belonging</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>47957.0</td>\n      <td>lowercase</td>\n      <td>a</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050773</th>\n      <td>1048553</td>\n      <td>nearbi</td>\n      <td>villag</td>\n      <td>.</td>\n      <td>.</td>\n      <td>punct</td>\n      <td>.</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>village</td>\n      <td>...</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>lowercase</td>\n      <td>a</td>\n      <td>47957.0</td>\n      <td>lowercase</td>\n      <td>nearby</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050774</th>\n      <td>1048554</td>\n      <td>villag</td>\n      <td>.</td>\n      <td>__end1__</td>\n      <td>__END1__</td>\n      <td>wildcard</td>\n      <td>__END1__</td>\n      <td>.</td>\n      <td>punct</td>\n      <td>.</td>\n      <td>...</td>\n      <td>a</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>a</td>\n      <td>lowercase</td>\n      <td>nearby</td>\n      <td>47957.0</td>\n      <td>lowercase</td>\n      <td>village</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050775</th>\n      <td>1048555</td>\n      <td>.</td>\n      <td>__end1__</td>\n      <td>__end2__</td>\n      <td>__END2__</td>\n      <td>wildcard</td>\n      <td>__END2__</td>\n      <td>__END1__</td>\n      <td>wildcard</td>\n      <td>__END1__</td>\n      <td>...</td>\n      <td>nearbi</td>\n      <td>JJ</td>\n      <td>lowercase</td>\n      <td>nearby</td>\n      <td>lowercase</td>\n      <td>village</td>\n      <td>47957.0</td>\n      <td>punct</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050776</th>\n      <td>1048556</td>\n      <td>they</td>\n      <td>say</td>\n      <td>not</td>\n      <td>RB</td>\n      <td>lowercase</td>\n      <td>not</td>\n      <td>VBP</td>\n      <td>lowercase</td>\n      <td>say</td>\n      <td>...</td>\n      <td>__start2__</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>47958.0</td>\n      <td>capitalized</td>\n      <td>They</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050777</th>\n      <td>1048557</td>\n      <td>say</td>\n      <td>not</td>\n      <td>all</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>all</td>\n      <td>RB</td>\n      <td>lowercase</td>\n      <td>not</td>\n      <td>...</td>\n      <td>__start1__</td>\n      <td>__START1__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>capitalized</td>\n      <td>They</td>\n      <td>47958.0</td>\n      <td>lowercase</td>\n      <td>say</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050778</th>\n      <td>1048558</td>\n      <td>not</td>\n      <td>all</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>all</td>\n      <td>...</td>\n      <td>they</td>\n      <td>PRP</td>\n      <td>capitalized</td>\n      <td>They</td>\n      <td>lowercase</td>\n      <td>say</td>\n      <td>47958.0</td>\n      <td>lowercase</td>\n      <td>not</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050779</th>\n      <td>1048559</td>\n      <td>all</td>\n      <td>of</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>...</td>\n      <td>say</td>\n      <td>VBP</td>\n      <td>lowercase</td>\n      <td>say</td>\n      <td>lowercase</td>\n      <td>not</td>\n      <td>47958.0</td>\n      <td>lowercase</td>\n      <td>all</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050780</th>\n      <td>1048560</td>\n      <td>of</td>\n      <td>the</td>\n      <td>rocket</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>rockets</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>...</td>\n      <td>not</td>\n      <td>RB</td>\n      <td>lowercase</td>\n      <td>not</td>\n      <td>lowercase</td>\n      <td>all</td>\n      <td>47958.0</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050781</th>\n      <td>1048561</td>\n      <td>the</td>\n      <td>rocket</td>\n      <td>explod</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>exploded</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>rockets</td>\n      <td>...</td>\n      <td>all</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>all</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>47958.0</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050782</th>\n      <td>1048562</td>\n      <td>rocket</td>\n      <td>explod</td>\n      <td>upon</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>upon</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>exploded</td>\n      <td>...</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>47958.0</td>\n      <td>lowercase</td>\n      <td>rockets</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050783</th>\n      <td>1048563</td>\n      <td>explod</td>\n      <td>upon</td>\n      <td>impact</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>impact</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>upon</td>\n      <td>...</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>lowercase</td>\n      <td>rockets</td>\n      <td>47958.0</td>\n      <td>lowercase</td>\n      <td>exploded</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050784</th>\n      <td>1048564</td>\n      <td>upon</td>\n      <td>impact</td>\n      <td>.</td>\n      <td>.</td>\n      <td>punct</td>\n      <td>.</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>impact</td>\n      <td>...</td>\n      <td>rocket</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>rockets</td>\n      <td>lowercase</td>\n      <td>exploded</td>\n      <td>47958.0</td>\n      <td>lowercase</td>\n      <td>upon</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050785</th>\n      <td>1048565</td>\n      <td>impact</td>\n      <td>.</td>\n      <td>__end1__</td>\n      <td>__END1__</td>\n      <td>wildcard</td>\n      <td>__END1__</td>\n      <td>.</td>\n      <td>punct</td>\n      <td>.</td>\n      <td>...</td>\n      <td>explod</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>exploded</td>\n      <td>lowercase</td>\n      <td>upon</td>\n      <td>47958.0</td>\n      <td>lowercase</td>\n      <td>impact</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050786</th>\n      <td>1048566</td>\n      <td>.</td>\n      <td>__end1__</td>\n      <td>__end2__</td>\n      <td>__END2__</td>\n      <td>wildcard</td>\n      <td>__END2__</td>\n      <td>__END1__</td>\n      <td>wildcard</td>\n      <td>__END1__</td>\n      <td>...</td>\n      <td>upon</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>upon</td>\n      <td>lowercase</td>\n      <td>impact</td>\n      <td>47958.0</td>\n      <td>punct</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050787</th>\n      <td>1048567</td>\n      <td>indian</td>\n      <td>forc</td>\n      <td>said</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>said</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>forces</td>\n      <td>...</td>\n      <td>__start2__</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>47959.0</td>\n      <td>capitalized</td>\n      <td>Indian</td>\n      <td>B-gpe</td>\n    </tr>\n    <tr>\n      <th>1050788</th>\n      <td>1048568</td>\n      <td>forc</td>\n      <td>said</td>\n      <td>they</td>\n      <td>PRP</td>\n      <td>lowercase</td>\n      <td>they</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>said</td>\n      <td>...</td>\n      <td>__start1__</td>\n      <td>__START1__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>capitalized</td>\n      <td>Indian</td>\n      <td>47959.0</td>\n      <td>lowercase</td>\n      <td>forces</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050789</th>\n      <td>1048569</td>\n      <td>said</td>\n      <td>they</td>\n      <td>respond</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>responded</td>\n      <td>PRP</td>\n      <td>lowercase</td>\n      <td>they</td>\n      <td>...</td>\n      <td>indian</td>\n      <td>JJ</td>\n      <td>capitalized</td>\n      <td>Indian</td>\n      <td>lowercase</td>\n      <td>forces</td>\n      <td>47959.0</td>\n      <td>lowercase</td>\n      <td>said</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050790</th>\n      <td>1048570</td>\n      <td>they</td>\n      <td>respond</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>responded</td>\n      <td>...</td>\n      <td>forc</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>forces</td>\n      <td>lowercase</td>\n      <td>said</td>\n      <td>47959.0</td>\n      <td>lowercase</td>\n      <td>they</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050791</th>\n      <td>1048571</td>\n      <td>respond</td>\n      <td>to</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>TO</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>...</td>\n      <td>said</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>said</td>\n      <td>lowercase</td>\n      <td>they</td>\n      <td>47959.0</td>\n      <td>lowercase</td>\n      <td>responded</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050792</th>\n      <td>1048572</td>\n      <td>to</td>\n      <td>the</td>\n      <td>attack</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>attack</td>\n      <td>DT</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>...</td>\n      <td>they</td>\n      <td>PRP</td>\n      <td>lowercase</td>\n      <td>they</td>\n      <td>lowercase</td>\n      <td>responded</td>\n      <td>47959.0</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050793</th>\n      <td>1048573</td>\n      <td>the</td>\n      <td>attack</td>\n      <td>with</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>with</td>\n      <td>NN</td>\n      <td>lowercase</td>\n      <td>attack</td>\n      <td>...</td>\n      <td>respond</td>\n      <td>VBD</td>\n      <td>lowercase</td>\n      <td>responded</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>47959.0</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1050794</th>\n      <td>1048574</td>\n      <td>attack</td>\n      <td>with</td>\n      <td>machine-gun</td>\n      <td>JJ</td>\n      <td>contains-hyphen</td>\n      <td>machine-gun</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>with</td>\n      <td>...</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>lowercase</td>\n      <td>to</td>\n      <td>lowercase</td>\n      <td>the</td>\n      <td>47959.0</td>\n      <td>lowercase</td>\n      <td>attack</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>1050795 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"06f00bc1-4964-46e9-a1ff-aa04d2605cef","_uuid":"d64e89af977c30f36cb50f590645ead8576d17ab"},"cell_type":"markdown","source":"## Data preprocessing"},{"metadata":{"_cell_guid":"85bfa964-b5c4-44d9-9cdc-9eb15259d7c9","_uuid":"028f9857d08bd173ac2a4b587ebd6975aa3c3e80","trusted":true},"cell_type":"code","source":"dframe.columns","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"Index(['Unnamed: 0', 'lemma', 'next-lemma', 'next-next-lemma', 'next-next-pos',\n       'next-next-shape', 'next-next-word', 'next-pos', 'next-shape',\n       'next-word', 'pos', 'prev-iob', 'prev-lemma', 'prev-pos',\n       'prev-prev-iob', 'prev-prev-lemma', 'prev-prev-pos', 'prev-prev-shape',\n       'prev-prev-word', 'prev-shape', 'prev-word', 'sentence_idx', 'shape',\n       'word', 'tag'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"_cell_guid":"e3448ee3-bed0-4029-88a1-3a79abfd23d5","_uuid":"2d4d560f8101eb4da1a90c05cfa30b32b134be10"},"cell_type":"markdown","source":"## We want word, pos, sentence_idx and tag as an input "},{"metadata":{"_cell_guid":"9f70ec09-0452-495d-aa80-a6358c2d30af","_uuid":"45e7b565a3eacf62a3104969026eed96c7440b34","trusted":true},"cell_type":"code","source":"dataset=dframe.drop(['Unnamed: 0', 'lemma', 'next-lemma', 'next-next-lemma', 'next-next-pos',\n       'next-next-shape', 'next-next-word', 'next-pos', 'next-shape',\n       'next-word', 'prev-iob', 'prev-lemma', 'prev-pos',\n       'prev-prev-iob', 'prev-prev-lemma', 'prev-prev-pos', 'prev-prev-shape',\n       'prev-prev-word', 'prev-shape', 'prev-word',\"pos\"],axis=1)","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"fbf18f0c-635d-495a-81a2-46cffd0a1141","_uuid":"fc7378e8db3c58bb9f953abf4991b0166a582373","trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":7,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1050795 entries, 0 to 1050794\nData columns (total 4 columns):\nsentence_idx    1050794 non-null float64\nshape           1050794 non-null object\nword            1050794 non-null object\ntag             1050794 non-null object\ndtypes: float64(1), object(3)\nmemory usage: 32.1+ MB\n","name":"stdout"}]},{"metadata":{"_cell_guid":"8d992370-b7b0-46d1-939c-74c567c23162","_uuid":"ab6642a1268a00928aa8651037ed84db5414b5f0","trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"   sentence_idx        shape           word tag\n0           1.0  capitalized      Thousands   O\n1           1.0    lowercase             of   O\n2           1.0    lowercase  demonstrators   O\n3           1.0    lowercase           have   O\n4           1.0    lowercase        marched   O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_idx</th>\n      <th>shape</th>\n      <th>word</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>capitalized</td>\n      <td>Thousands</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>have</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>marched</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"4d20e995-322b-4928-85e1-38385b8e8753","_uuid":"8d47f338cf116e591449949652de2f09a1d402c3","trusted":true},"cell_type":"code","source":"dataset=dataset.drop(['shape'],axis=1)","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"768177ab-ed36-46d2-ba06-49b708dbe185","_uuid":"744cc63a695f486351f214f272307656c77db95d","trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"   sentence_idx           word tag\n0           1.0      Thousands   O\n1           1.0             of   O\n2           1.0  demonstrators   O\n3           1.0           have   O\n4           1.0        marched   O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_idx</th>\n      <th>word</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>Thousands</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>demonstrators</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>have</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>marched</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"ba6f0e4d-4b1e-40fa-a72a-df2502841ae4","_uuid":"e5c4b55af4bce4308671e8a611c65bf64d0f0678"},"cell_type":"markdown","source":"## Create list of list of tuples to differentiate each sentence from each other"},{"metadata":{"_cell_guid":"6cab4e05-47c2-4c5b-bcbb-f899f0639691","_uuid":"198ccf9cc26eca32fd8e17b7f3e41bf0af3612b1","trusted":true},"cell_type":"code","source":"class SentenceGetter(object):\n    \n    def __init__(self, dataset):\n        self.n_sent = 1\n        self.dataset = dataset\n        self.empty = False\n        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n                                                        s[\"tag\"].values.tolist())]\n        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n        self.sentences = [s for s in self.grouped]\n    \n    def get_next(self):\n        try:\n            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"16006628-505a-4d37-a5f6-db6a428517b4","_uuid":"fb62acd5794185e2d7714e76712af2ed2ccc6c1d","trusted":true},"cell_type":"code","source":"getter = SentenceGetter(dataset)","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"5d0f958e-ac9c-41cb-a4bc-0256525d4f21","_uuid":"88c8e7bc1b13eac9cffc3a8c4e17b27f116e5776","trusted":true},"cell_type":"code","source":"sentences = getter.sentences","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"e33a8086-5906-45b4-8091-2ff97a48d180","_uuid":"d8ef748ceed29d08cab896e10e173ffa750d402c","trusted":true},"cell_type":"code","source":"print(sentences[5])\nprint(len(sentences))","execution_count":14,"outputs":[{"output_type":"stream","text":"[('The', 'O'), ('party', 'O'), ('is', 'O'), ('divided', 'O'), ('over', 'O'), ('Britain', 'B-gpe'), (\"'s\", 'O'), ('participation', 'O'), ('in', 'O'), ('the', 'O'), ('Iraq', 'B-geo'), ('conflict', 'O'), ('and', 'O'), ('the', 'O'), ('continued', 'O'), ('deployment', 'O'), ('of', 'O'), ('8,500', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('in', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O'), ('The', 'O'), ('party', 'O'), ('is', 'O'), ('divided', 'O'), ('over', 'O'), ('Britain', 'B-gpe'), (\"'s\", 'O'), ('participation', 'O'), ('in', 'O'), ('the', 'O'), ('Iraq', 'B-geo'), ('conflict', 'O'), ('and', 'O'), ('the', 'O'), ('continued', 'O'), ('deployment', 'O'), ('of', 'O'), ('8,500', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('in', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n35177\n","name":"stdout"}]},{"metadata":{"_cell_guid":"88cb5e40-fe8a-47a9-9be2-a23340c28a5c","_uuid":"2f4479487f075f8c196a7af9ffaf5dd943a1326d","trusted":true},"cell_type":"code","source":"maxlen = max([len(s) for s in sentences])\nprint ('Maximum sequence length:', maxlen)","execution_count":15,"outputs":[{"output_type":"stream","text":"Maximum sequence length: 140\n","name":"stdout"}]},{"metadata":{"_cell_guid":"263e86f4-2605-4b1f-b3df-e3c42f1c9ec4","_uuid":"ef272f6ecc6b8637ebe644b1982f17c41f190039","trusted":true},"cell_type":"code","source":"# Check how long sentences are so that we can pad them\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use(\"ggplot\")","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"61e67c66-cd9f-481f-a1ea-a78815dfed47","_uuid":"f25daa9b0767a04690f14ba99ed5730c71cb2100","trusted":true},"cell_type":"code","source":"plt.hist([len(s) for s in sentences], bins=50)\nplt.show()","execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"_cell_guid":"4efea2e0-276c-44bb-b0ce-c94ac99cbf91","_uuid":"db68187a5ea707569031c83db34ca4284025bb8b","trusted":true},"cell_type":"code","source":"words = list(set(dataset[\"word\"].values))\nwords.append(\"ENDPAD\")","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"5b3697b0-0e7d-4265-9fd1-8001792e6fa5","_uuid":"139a721c0b0036e9cc97892ab8d3d2c3ea0ebafa","trusted":true},"cell_type":"code","source":"n_words = len(words); n_words","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"30174"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Fix the tags"},{"metadata":{"_cell_guid":"2dc974c3-e5df-45dd-9aff-f8ec43e52399","_uuid":"b51ed46f6c6956fc92a71033c82d804455a01e3d","trusted":true},"cell_type":"code","source":"tags = []\nfor tag in set(dataset[\"tag\"].values):\n    if tag is nan or isinstance(tag, float):\n        tags.append('unk')\n    else:\n        tags.append(tag)\nprint(tags)","execution_count":20,"outputs":[{"output_type":"stream","text":"['B-geo', 'B-gpe', 'I-per', 'I-org', 'I-gpe', 'unk', 'B-tim', 'B-per', 'I-nat', 'I-eve', 'O', 'B-art', 'I-tim', 'B-nat', 'B-org', 'I-geo', 'B-eve', 'I-art']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"6cd182c7-7f68-420b-b10f-121da695184e","_uuid":"a426a4acd9481ef8618830c9265f4887d63ec9b5","trusted":true},"cell_type":"code","source":"n_tags = len(tags); n_tags","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"18"},"metadata":{}}]},{"metadata":{"_cell_guid":"15e92312-4539-490c-a34a-8d8c91e97e0e","_uuid":"8d7134b27205443861225d5820d2ac9e0049e30e"},"cell_type":"markdown","source":"**Converting words to numbers and numbers to words**"},{"metadata":{"_cell_guid":"805f61f0-ec6b-4afc-a1f6-60a5fe015023","_uuid":"b8109f08b55281540b01c07d95666b2f413aa0a8","trusted":true},"cell_type":"code","source":"from future.utils import iteritems\nword2idx = {w: i for i, w in enumerate(words)}\ntag2idx = {t: i for i, t in enumerate(tags)}\nidx2tag = {v: k for k, v in iteritems(tag2idx)}\n\nprint(tag2idx)","execution_count":22,"outputs":[{"output_type":"stream","text":"{'B-geo': 0, 'B-gpe': 1, 'I-per': 2, 'I-org': 3, 'I-gpe': 4, 'unk': 5, 'B-tim': 6, 'B-per': 7, 'I-nat': 8, 'I-eve': 9, 'O': 10, 'B-art': 11, 'I-tim': 12, 'B-nat': 13, 'B-org': 14, 'I-geo': 15, 'B-eve': 16, 'I-art': 17}\n","name":"stdout"}]},{"metadata":{"_cell_guid":"36b9e479-e006-4d4d-9d0b-fbaf6c89db77","_uuid":"28bf99df1f14a53181bb3eade1ebf68f1d2f8cf8","trusted":true},"cell_type":"code","source":"word2idx['Obama']","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"13749"},"metadata":{}}]},{"metadata":{"_cell_guid":"7e614013-5dd7-4309-b481-7a12b881d8f6","_uuid":"8bca49f998176bfa05a21ebd22822066063184b1","trusted":true},"cell_type":"code","source":"tag2idx[\"O\"]","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"10"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tag2idx","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"{'B-geo': 0,\n 'B-gpe': 1,\n 'I-per': 2,\n 'I-org': 3,\n 'I-gpe': 4,\n 'unk': 5,\n 'B-tim': 6,\n 'B-per': 7,\n 'I-nat': 8,\n 'I-eve': 9,\n 'O': 10,\n 'B-art': 11,\n 'I-tim': 12,\n 'B-nat': 13,\n 'B-org': 14,\n 'I-geo': 15,\n 'B-eve': 16,\n 'I-art': 17}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx2tag[5]","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"'unk'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx2tag","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"{0: 'B-geo',\n 1: 'B-gpe',\n 2: 'I-per',\n 3: 'I-org',\n 4: 'I-gpe',\n 5: 'unk',\n 6: 'B-tim',\n 7: 'B-per',\n 8: 'I-nat',\n 9: 'I-eve',\n 10: 'O',\n 11: 'B-art',\n 12: 'I-tim',\n 13: 'B-nat',\n 14: 'B-org',\n 15: 'I-geo',\n 16: 'B-eve',\n 17: 'I-art'}"},"metadata":{}}]},{"metadata":{"_cell_guid":"5cd7d9ad-77ae-49ba-b99e-6429a949dede","_uuid":"b25bb0979a6bbe8c6eb11b05c23109592d318a5b","trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nX = [[word2idx[w[0]] for w in s] for s in sentences]","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(X).shape","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"(35177,)"},"metadata":{}}]},{"metadata":{"_cell_guid":"c3ff7a53-4e1b-4b82-bf2e-d581dbdc4315","_uuid":"75ab049dc0c8a6408913da28666c21ac6f9385d3","trusted":true},"cell_type":"code","source":"X = pad_sequences(maxlen=140, sequences=X, padding=\"post\",value=n_words - 1)","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"5d331c3d-a729-454d-ba92-2f3540e3ecac","_uuid":"50607669ece7f12df2be2836193540a0375d848d","trusted":true},"cell_type":"code","source":"y_idx = [[tag2idx[w[1]] for w in s] for s in sentences]\nprint(sentences[100])\nprint(y_idx[100])","execution_count":31,"outputs":[{"output_type":"stream","text":"[('The', 'O'), ('Pakistani', 'B-gpe'), ('military', 'O'), ('launched', 'O'), ('its', 'O'), ('offensive', 'O'), ('in', 'O'), ('Orakzai', 'B-geo'), ('to', 'O'), ('hunt', 'O'), ('Taliban', 'B-org'), ('insurgents', 'O'), ('.', 'O'), ('The', 'O'), ('Pakistani', 'B-gpe'), ('military', 'O'), ('launched', 'O'), ('its', 'O'), ('offensive', 'O'), ('in', 'O'), ('Orakzai', 'B-geo'), ('to', 'O'), ('hunt', 'O'), ('Taliban', 'B-org'), ('insurgents', 'O'), ('.', 'O')]\n[10, 1, 10, 10, 10, 10, 10, 0, 10, 10, 14, 10, 10, 10, 1, 10, 10, 10, 10, 10, 0, 10, 10, 14, 10, 10]\n","name":"stdout"}]},{"metadata":{"_cell_guid":"8ee02d57-7dc2-4516-9f3b-42507d1d7369","_uuid":"61183c55adee810a0b161cbdfa2a6024862251a4","trusted":true},"cell_type":"code","source":"y = pad_sequences(maxlen=140, sequences=y_idx, padding=\"post\", value=tag2idx[\"O\"])\nprint(y_idx[100])\n","execution_count":32,"outputs":[{"output_type":"stream","text":"[10, 1, 10, 10, 10, 10, 10, 0, 10, 10, 14, 10, 10, 10, 1, 10, 10, 10, 10, 10, 0, 10, 10, 14, 10, 10]\n","name":"stdout"}]},{"metadata":{"_cell_guid":"75b64d49-10a1-411c-85bc-5861a257670e","_uuid":"bd9a39278a2010d51ff4f4a9ccbf0df1d6ee5612","trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ny = [to_categorical(i, num_classes=n_tags) for i in y]\n","execution_count":33,"outputs":[]},{"metadata":{"_cell_guid":"b33bf24e-22cb-4cf4-b504-e84f0ccc84e5","_uuid":"75c39949b2cce357b15f5c42f73421a4b0116de5","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","execution_count":34,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Keras"},{"metadata":{"_cell_guid":"00a15ead-883e-4348-96df-e86dcb65a945","_uuid":"89375c4a136104777c96a13b02d2810d78bcc1d9","trusted":true},"cell_type":"code","source":"from keras.models import Model, Input\nfrom keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\nimport keras as k","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keras version"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(k.__version__)","execution_count":36,"outputs":[{"output_type":"stream","text":"2.2.4\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Model\n **Pay attention to the word embedding size"},{"metadata":{"trusted":true},"cell_type":"code","source":"input = Input(shape=(140,))\nword_embedding_size = 300\nmodel = Embedding(input_dim=n_words, output_dim=word_embedding_size, input_length=140)(input)\nmodel = Bidirectional(LSTM(units=word_embedding_size, \n                           return_sequences=True, \n                           dropout=0.5, \n                           recurrent_dropout=0.5, \n                           kernel_initializer=k.initializers.he_normal()))(model)\nmodel = LSTM(units=word_embedding_size * 2, \n             return_sequences=True, \n             dropout=0.5, \n             recurrent_dropout=0.5, \n             kernel_initializer=k.initializers.he_normal())(model)\nmodel = TimeDistributed(Dense(n_tags, activation=\"relu\"))(model)  # previously softmax output layer\n\ncrf = CRF(n_tags)  # CRF layer\nout = crf(model)  # output","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"82ffe0e4-30f4-49a7-902a-e1942ca59259","_uuid":"d9ec4a0fd80b49f9bb28a25de022ec848113fa9a","trusted":true},"cell_type":"code","source":"model = Model(input, out)","execution_count":38,"outputs":[]},{"metadata":{"_cell_guid":"bf8e202b-f374-42c0-9a8f-146d595c8648","_uuid":"93300d6dc8ac67eecd8f99f2ee82d2817daf5f96","trusted":true},"cell_type":"code","source":"adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n#model.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])","execution_count":39,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n  warnings.warn('CRF.loss_function is deprecated '\n/opt/conda/lib/python3.6/site-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n  warnings.warn('CRF.accuracy is deprecated and it '\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":40,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 140)               0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 140, 300)          9052200   \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 140, 600)          1442400   \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 140, 600)          2882400   \n_________________________________________________________________\ntime_distributed_1 (TimeDist (None, 140, 18)           10818     \n_________________________________________________________________\ncrf_1 (CRF)                  (None, 140, 18)           702       \n=================================================================\nTotal params: 13,388,520\nTrainable params: 13,388,520\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Save the model after each epoch if validation is better"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the best only\nfilepath=\"ner-bi-lstm-td-model-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]","execution_count":41,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fit"},{"metadata":{"_cell_guid":"5df5d6eb-2285-4a57-b5a0-d0bcbf79c483","_uuid":"93e241a9304d00294cb0f675f1e42b5dbb6a1c07","trusted":true,"scrolled":true},"cell_type":"code","source":"history = model.fit(X_train, np.array(y_train), batch_size=256, epochs=20, validation_split=0.2, verbose=1, callbacks=callbacks_list)","execution_count":42,"outputs":[{"output_type":"stream","text":"Train on 22512 samples, validate on 5629 samples\nEpoch 1/20\n22512/22512 [==============================] - 119s 5ms/step - loss: 0.3962 - crf_viterbi_accuracy: 0.9272 - acc: 0.0075 - val_loss: 0.1885 - val_crf_viterbi_accuracy: 0.9668 - val_acc: 0.9668\n\nEpoch 00001: val_acc improved from -inf to 0.96684, saving model to ner-bi-lstm-td-model-0.97.hdf5\nEpoch 2/20\n22512/22512 [==============================] - 106s 5ms/step - loss: 0.1604 - crf_viterbi_accuracy: 0.9674 - acc: 0.0075 - val_loss: 0.1300 - val_crf_viterbi_accuracy: 0.9669 - val_acc: 0.9669\n\nEpoch 00002: val_acc improved from 0.96684 to 0.96689, saving model to ner-bi-lstm-td-model-0.97.hdf5\nEpoch 3/20\n22512/22512 [==============================] - 105s 5ms/step - loss: 0.1026 - crf_viterbi_accuracy: 0.9697 - acc: 0.0075 - val_loss: 0.0859 - val_crf_viterbi_accuracy: 0.9744 - val_acc: 0.9744\n\nEpoch 00003: val_acc improved from 0.96689 to 0.97442, saving model to ner-bi-lstm-td-model-0.97.hdf5\nEpoch 4/20\n22512/22512 [==============================] - 105s 5ms/step - loss: 0.0763 - crf_viterbi_accuracy: 0.9768 - acc: 0.0075 - val_loss: 0.0729 - val_crf_viterbi_accuracy: 0.9788 - val_acc: 0.9788\n\nEpoch 00004: val_acc improved from 0.97442 to 0.97880, saving model to ner-bi-lstm-td-model-0.98.hdf5\nEpoch 5/20\n22512/22512 [==============================] - 105s 5ms/step - loss: 0.0638 - crf_viterbi_accuracy: 0.9804 - acc: 0.0075 - val_loss: 0.0633 - val_crf_viterbi_accuracy: 0.9812 - val_acc: 0.9812\n\nEpoch 00005: val_acc improved from 0.97880 to 0.98115, saving model to ner-bi-lstm-td-model-0.98.hdf5\nEpoch 6/20\n22512/22512 [==============================] - 103s 5ms/step - loss: 0.0529 - crf_viterbi_accuracy: 0.9843 - acc: 0.0075 - val_loss: 0.0549 - val_crf_viterbi_accuracy: 0.9858 - val_acc: 0.9858\n\nEpoch 00006: val_acc improved from 0.98115 to 0.98577, saving model to ner-bi-lstm-td-model-0.99.hdf5\nEpoch 7/20\n22512/22512 [==============================] - 104s 5ms/step - loss: 0.0443 - crf_viterbi_accuracy: 0.9876 - acc: 0.0075 - val_loss: 0.0486 - val_crf_viterbi_accuracy: 0.9876 - val_acc: 0.9876\n\nEpoch 00007: val_acc improved from 0.98577 to 0.98759, saving model to ner-bi-lstm-td-model-0.99.hdf5\nEpoch 8/20\n22512/22512 [==============================] - 105s 5ms/step - loss: 0.0372 - crf_viterbi_accuracy: 0.9897 - acc: 0.0075 - val_loss: 0.0425 - val_crf_viterbi_accuracy: 0.9888 - val_acc: 0.9888\n\nEpoch 00008: val_acc improved from 0.98759 to 0.98881, saving model to ner-bi-lstm-td-model-0.99.hdf5\nEpoch 9/20\n22512/22512 [==============================] - 109s 5ms/step - loss: 0.0313 - crf_viterbi_accuracy: 0.9913 - acc: 0.0075 - val_loss: 0.0390 - val_crf_viterbi_accuracy: 0.9898 - val_acc: 0.9898\n\nEpoch 00009: val_acc improved from 0.98881 to 0.98983, saving model to ner-bi-lstm-td-model-0.99.hdf5\nEpoch 10/20\n22512/22512 [==============================] - 105s 5ms/step - loss: 0.0265 - crf_viterbi_accuracy: 0.9924 - acc: 0.0075 - val_loss: 0.0355 - val_crf_viterbi_accuracy: 0.9905 - val_acc: 0.9905\n\nEpoch 00010: val_acc improved from 0.98983 to 0.99051, saving model to ner-bi-lstm-td-model-0.99.hdf5\nEpoch 11/20\n22512/22512 [==============================] - 107s 5ms/step - loss: 0.0226 - crf_viterbi_accuracy: 0.9934 - acc: 0.0075 - val_loss: 0.0326 - val_crf_viterbi_accuracy: 0.9912 - val_acc: 0.9912\n\nEpoch 00011: val_acc improved from 0.99051 to 0.99115, saving model to ner-bi-lstm-td-model-0.99.hdf5\nEpoch 12/20\n22512/22512 [==============================] - 108s 5ms/step - loss: 0.0198 - crf_viterbi_accuracy: 0.9941 - acc: 0.0075 - val_loss: 0.0311 - val_crf_viterbi_accuracy: 0.9911 - val_acc: 0.9911\n\nEpoch 00012: val_acc did not improve from 0.99115\nEpoch 13/20\n22512/22512 [==============================] - 107s 5ms/step - loss: 0.0176 - crf_viterbi_accuracy: 0.9945 - acc: 0.0075 - val_loss: 0.0303 - val_crf_viterbi_accuracy: 0.9914 - val_acc: 0.9914\n\nEpoch 00013: val_acc improved from 0.99115 to 0.99140, saving model to ner-bi-lstm-td-model-0.99.hdf5\nEpoch 14/20\n22512/22512 [==============================] - 106s 5ms/step - loss: 0.0158 - crf_viterbi_accuracy: 0.9949 - acc: 0.0075 - val_loss: 0.0313 - val_crf_viterbi_accuracy: 0.9915 - val_acc: 0.9915\n\nEpoch 00014: val_acc improved from 0.99140 to 0.99151, saving model to ner-bi-lstm-td-model-0.99.hdf5\nEpoch 15/20\n22512/22512 [==============================] - 106s 5ms/step - loss: 0.0143 - crf_viterbi_accuracy: 0.9951 - acc: 0.0075 - val_loss: 0.0299 - val_crf_viterbi_accuracy: 0.9912 - val_acc: 0.9912\n\nEpoch 00015: val_acc did not improve from 0.99151\nEpoch 16/20\n22512/22512 [==============================] - 109s 5ms/step - loss: 0.0130 - crf_viterbi_accuracy: 0.9953 - acc: 0.0075 - val_loss: 0.0300 - val_crf_viterbi_accuracy: 0.9915 - val_acc: 0.9915\n\nEpoch 00016: val_acc did not improve from 0.99151\nEpoch 17/20\n22512/22512 [==============================] - 108s 5ms/step - loss: 0.0120 - crf_viterbi_accuracy: 0.9956 - acc: 0.0075 - val_loss: 0.0298 - val_crf_viterbi_accuracy: 0.9915 - val_acc: 0.9915\n\nEpoch 00017: val_acc did not improve from 0.99151\nEpoch 18/20\n22512/22512 [==============================] - 108s 5ms/step - loss: 0.0109 - crf_viterbi_accuracy: 0.9958 - acc: 0.0075 - val_loss: 0.0299 - val_crf_viterbi_accuracy: 0.9915 - val_acc: 0.9915\n\nEpoch 00018: val_acc improved from 0.99151 to 0.99155, saving model to ner-bi-lstm-td-model-0.99.hdf5\nEpoch 19/20\n22512/22512 [==============================] - 107s 5ms/step - loss: 0.0098 - crf_viterbi_accuracy: 0.9960 - acc: 0.0075 - val_loss: 0.0300 - val_crf_viterbi_accuracy: 0.9913 - val_acc: 0.9913\n\nEpoch 00019: val_acc did not improve from 0.99155\nEpoch 20/20\n22512/22512 [==============================] - 106s 5ms/step - loss: 0.0089 - crf_viterbi_accuracy: 0.9961 - acc: 0.0075 - val_loss: 0.0290 - val_crf_viterbi_accuracy: 0.9914 - val_acc: 0.9914\n\nEpoch 00020: val_acc did not improve from 0.99155\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Accumulate metrics by tag "},{"metadata":{"trusted":true},"cell_type":"code","source":"TP = {}\nTN = {}\nFP = {}\nFN = {}\nfor tag in tag2idx.keys():\n    TP[tag] = 0\n    TN[tag] = 0    \n    FP[tag] = 0    \n    FN[tag] = 0    \n\nprint(\"??\")\ndef accumulate_score_by_tag(gt, pred):\n    \"\"\"\n    For each tag keep stats\n    \"\"\"\n    if gt == pred:\n        TP[gt] += 1\n    elif gt != 'O' and pred == 'O':\n        FN[gt] +=1\n    elif gt == 'O' and pred != 'O':\n        FP[gt] += 1\n    else:\n        TN[gt] += 1\n\nprint(\"?\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Single prediction and verbose results"},{"metadata":{"trusted":true,"_uuid":"139269e019aaac2da260b0ee5a676a4c618f6673"},"cell_type":"code","source":"i = 357\np = model.predict(np.array([X_test[i]]))\np = np.argmax(p, axis=-1)\ngt = np.argmax(y_test[i], axis=-1)\nprint(gt)\nprint(\"{:14}: ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\nfor idx, (w,pred) in enumerate(zip(X_test[i],p[0])):\n    #\n    print(\"{:14}: ({:5}): {}\".format(words[w],idx2tag[gt[idx]],tags[pred]))","execution_count":44,"outputs":[{"output_type":"stream","text":"[10 10 10 10 14  3  7  2 10 10 10 10  0 10 10  6 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\nWord          : (True ): Pred\nThe           : (O    ): O\nstatement     : (O    ): O\ncame          : (O    ): O\nas            : (O    ): O\nU.N.          : (B-org): B-org\nSecretary-General: (I-org): I-org\nKofi          : (B-per): B-per\nAnnan         : (I-per): I-per\nmet           : (O    ): O\nwith          : (O    ): O\nofficials     : (O    ): O\nin            : (O    ): O\nAmman         : (B-geo): B-geo\nto            : (O    ): O\ndiscuss       : (O    ): O\nWednesday     : (B-tim): B-tim\n's            : (O    ): O\nattacks       : (O    ): O\n.             : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\nENDPAD        : (O    ): O\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Predict everything at once"},{"metadata":{"trusted":true},"cell_type":"code","source":"p = model.predict(np.array(X_test))  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The output is 3d: sent x word x tag prob (softmax)"},{"metadata":{"trusted":true},"cell_type":"code","source":"p.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standard Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grab the 3d dimension and return the index of the highest probability ... the index matches the tag value\nnp.argmax(p, axis=2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(p, axis=2)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(np.argmax(y_test, 2).ravel(), np.argmax(p, axis=2).ravel(),labels=list(idx2tag.keys()), target_names=list(idx2tag.values())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accumulate the scores by tag"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, sentence in enumerate(X_test):\n    y_hat = np.argmax(p[i], axis=-1)\n    gt = np.argmax(y_test[i], axis=-1)\n    for idx, (w,pred) in enumerate(zip(sentence,y_hat)):\n        accumulate_score_by_tag(idx2tag[gt[idx]],tags[pred])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How did Classification perform for each tag"},{"metadata":{"trusted":true},"cell_type":"code","source":"for tag in tag2idx.keys():\n    print(f'tag:{tag}')    \n    print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag],FP[tag]))\n    print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag],TP[tag]))    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}